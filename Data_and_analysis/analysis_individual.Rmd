---
title: "WordRec Experiment"
author: "A. Fourtassi & M. Frank"
date: "January 13, 2017"
output:
  html_document:
    number_sections: yes
    toc: yes
---

Libraries.

```{r}
#library(papaja)
library(broom)
  library(purrr)
  library(readr)
  library(ggplot2)
  library(dplyr)
  library(tidyr)
  #library(wordbankr)
  library(stringr)
  library(feather)
  library(lme4)
  library(boot)
  library(langcog)
  library(ggthemes)
  library(nlme)
  #library(rwebppl)
  library(jsonlite)
  library(Hmisc)
  library(poweRlaw)
  library(HDInterval)
  #library(kableExtra)
```

Data and processing
```{r}

#Skip the pre task trials 
#Filter subjects who had no technical problem
#Select subjects who got more than 50% correct answers on the pre task trials

exp1 <- read_delim("exp1_rev2_anonym.txt", delim = " ") %>%
  filter(type == "Task") %>%
  mutate(experiment='Experiment1')

N_all_1 <- exp1 %>%
  distinct(ID) %>%
  nrow()
  
exp1_noProb <- exp1 %>%
  filter(problem=="No") 

N_noProb_1 <- exp1_noProb %>%
  distinct(ID) %>%
  nrow()

exp1_good <- exp1_noProb %>%
  filter(score > 0.5)

N_good_1 <- exp1_good %>%
  distinct(ID) %>%
  nrow()

sound_all_exp1 <- exp1_good %>%
    filter(condition == "sound")

concept_all_exp1 <- exp1_good %>%
    filter(condition == "concept")

joint_all_exp1 <- exp1_good %>%
    filter(condition == "joint")


```

Fit the aggregate  data 
```{r}
data_s <- sound_all_exp1 %>%
  group_by(sound_dist) %>%
  dplyr::summarise(mean = mean(answer),
                   sd = sd(answer),
                   n = n()) %>%
  mutate(se = sd / sqrt(n),
         lower = mean - qt(1 - (0.05 / 2), n - 1) * se,
         upper = mean + qt(1 - (0.05 / 2), n - 1) * se) %>%
  select(-sd, -n, -se,) %>%
  mutate(Experiment="Experiment 1", 
         Condition="Auditory") %>%
  rename(distance = sound_dist)

data_c <- concept_all_exp1 %>%
  group_by(concept_dist) %>%
  dplyr::summarise(mean = mean(answer),
                   sd = sd(answer),
                   n = n()) %>%
  mutate(se = sd / sqrt(n),
         lower = mean - qt(1 - (0.05 / 2), n - 1) * se,
         upper = mean + qt(1 - (0.05 / 2), n - 1) * se) %>%
  select(-sd, -n, -se,) %>%
  mutate(Experiment="Experiment 1", 
         Condition="Visual") %>%
  rename(distance = concept_dist)

data_j <- joint_all_exp1 %>%
  group_by(sound_dist, concept_dist) %>%
  dplyr::summarise(mean = mean(answer),
                   sd = sd(answer),
                   n = n()) %>%
  mutate(se = sd / sqrt(n),
         lower = mean - qt(1 - (0.05 / 2), n - 1) * se,
         upper = mean + qt(1 - (0.05 / 2), n - 1) * se) %>%
  select(-sd, -n, -se,) %>%
  mutate(Experiment="Experiment 1", 
         Condition="Joint") 

data_all <- bind_rows(data_s, data_c)

model_s <- nls(answer ~ 1/(1+(1-e)*exp((-4/vrA)*sound_dist+(8/vrA))), data=sound_all_exp1, start = list(e=0, vrA=2))
model_c <- nls(answer ~ 1/(1+(1-e)*exp((-4/vrV)*concept_dist+(8/vrV))), data=concept_all_exp1, start = list(e=0, vrV=2))
model_j <- nls(answer ~ 1/(1+(1-e)*exp((-4/vrA_j)*sound_dist+(-4/vrV_j)*concept_dist+(8/vrA_j)+(8/vrV_j))), data=joint_all_exp1, start = list(e=0, vrA_j=2, vrV_j=2))

#Plot the data here
x <- seq(0, 4, 0.01)

y_s <- predict(model_s, list(sound_dist = x), type="response")
y_c <- predict(model_c, list(concept_dist = x), type="response")

pred_all <- bind_rows(data.frame(distance=x, prediction=y_s, Condition = "Auditory"), 
                      data.frame(distance=x, prediction=y_c, Condition = "Visual")) 
  
#Derive values of the variance from the 
ggplot(data_all, 
       aes(x = distance, y = mean)) + 
  geom_point()+
  geom_pointrange(aes(ymin = lower, ymax = upper), 
                  position = position_dodge(width = .1), size = 0.4, fatten = 2) + 
  #geom_line(data=uniV,aes(x=xV, y=yV))+
  geom_line(data=pred_all, aes(x=distance, y=prediction), col='black')+
  #geom_line(data=uni_me_s, aes(x=distance, y=prediction), col='blue')+
  #geom_line(data=uni_nl_s, aes(x=distance, y=prediction), col='red')+
  xlab("Distance") +ylab("Prob. different")+
  scale_y_continuous(limits = c(0, 1))+#theme(aspect.ratio = 0.7)+
  theme_few()+
  theme(aspect.ratio = 0.7) + facet_grid(. ~ Condition)


```
Optimal model
```{r}
#Extract cefficieny

eA <- coefficients(model_s)["e"]
vrA <- coefficients(model_s)["vrA"]

eV <- coefficients(model_c)["e"]
vrV <- coefficients(model_c)["vrV"]

ej <- coefficients(model_j)["e"]
vrAj <- coefficients(model_j)["vrA_j"]
vrVj <- coefficients(model_j)["vrV_j"]

#The sound-only model
m_s <- function (x,y) {
  1/(1 + (1-eA)*exp((-4/vrA)*x+(8/vrA)))
}

#The visual-only model
m_c <- function (x,y) {
  1/(1 + (1-eV)*exp((-4/vrV)*y+(8/vrV)))
}

#Descriptive model (parameters are derived from fit to bimodal data)
m_opt <- function (x,y) {
   1/(1 + (1-ej)*exp((-4/vrA)*x+(-4/vrV)*y+(8/vrA)+(8/vrV)))
}

#The optimal model (parameters are derived from fit to unimodal data)
m_des <- function (x,y) {
    1/(1 + (1-ej)*exp((-4/vrAj)*x+(-4/vrVj)*y+(8/vrAj)+(8/vrVj)))
}

pred_all_comb <- data_j %>% 
  rename(joint = mean) %>%
  mutate(Descriptive = m_des(sound_dist, concept_dist)) %>%
  mutate(Optimal = m_opt(sound_dist, concept_dist)) %>%
  mutate(Auditory = m_s(sound_dist, concept_dist)) %>%
  mutate(Visual = m_c(sound_dist, concept_dist)) %>%
  gather(model, pred, Visual, Auditory, Optimal, Descriptive) %>%
  mutate(experiment = 'Experiment 1')


pred_all_comb$model <- factor(pred_all_comb$model, levels = c('Visual','Auditory', 'Optimal', 'Descriptive'))

correlations <- pred_all_comb %>%
  group_by(model) %>%
  summarise(cor = round(cor(joint, pred), 2))

ggplot(pred_all_comb, 
       aes(x = pred, y = joint)) +
           #col = factor(concept_dist), 
          # shape = factor(sound_dist))) + 
  geom_point(size =1)+
  scale_colour_solarized()+
 #geom_pointrange(aes(ymin = summary_ci_lower, ymax = summary_ci_upper), 
  #                position = position_dodge(width = .1), size=0.2) + 
  geom_abline(slope = 1, lty = 2) +
  xlab("Predictions") +ylab("Human data")+
  facet_grid(. ~ model)+
  theme_few()+
  geom_text(data=correlations, aes(label=paste("r=", cor, sep="")), x=0.5, y=0.95, size=2, fontface = "bold", col="red")+
theme(aspect.ratio = 0.7, 
      axis.text=element_text(size=6),
      strip.text.y = element_text(size = 8))+
  guides(color=guide_legend(title="Visual Distance")) +
  guides(shape=guide_legend(title="Auditory Distance")) 






```



Human data by subject
```{r}

sounds_exp1 <- exp1_good %>%
  filter(condition == "sound") %>%
  group_by(ID, sound_dist) %>%
  dplyr::summarise(mean = mean(answer),
                   sd = sd(answer),
                   n = n()) %>%
  mutate(se = sd / sqrt(n),
         lower = mean - qt(1 - (0.05 / 2), n - 1) * se,
         upper = mean + qt(1 - (0.05 / 2), n - 1) * se) %>%
  select(-sd, -n, -se,) %>%
  mutate(Experiment="Experiment 1", 
         Condition="Auditory") %>%
  rename(distance = sound_dist)

concepts_exp1 <- exp1_good %>%
  filter(condition == "concept") %>%
  group_by(ID, concept_dist) %>%
  dplyr::summarise(mean = mean(answer),
                   sd = sd(answer),
                   n = n()) %>%
  mutate(se = sd / sqrt(n),
         lower = mean - qt(1 - (0.05 / 2), n - 1) * se,
         upper = mean + qt(1 - (0.05 / 2), n - 1) * se) %>%
  select(-sd, -n, -se,) %>%
  mutate(Experiment="Experiment 1", 
         Condition="Visual") %>%
  rename(distance = concept_dist)


joint_exp1 <- exp1_good %>%
  filter(condition == "joint") %>%
  group_by(ID, concept_dist, sound_dist) %>%
  summarise(mean = mean(answer)) %>%
  mutate(Experiment="Experiment 1", 
         Condition="Joint")


exp_uni_data <- bind_rows(sounds_exp1, concepts_exp1)
```

Here fit the same models for every subject
```{r}

#Models 

#Sound Unimodal
fit_s <- function(data) {
  nls(answer ~ 1/(1+(1-e)*exp((-4/vrA)*sound_dist+(8/vrA))), 
                 data=data,
                 start = list(e=0, vrA=1),
                 nls.control(warnOnly = TRUE)) 
}
#Concept Unimodal
fit_c <- function(data) {
  nls(answer ~ 1/(1+(1-e)*exp((-4/vrV)*concept_dist+(8/vrV))), 
                 data=data,
                 start = list(e=0, vrV=1),
                 nls.control(warnOnly = TRUE)) 
}

#Joint sound-concept
fit_j <- function(data) {
  nls(answer ~1/(1+(1-e)*exp((-4/vrA_j)*sound_dist+(-4/vrV_j)*concept_dist+(8/vrA_j)+(8/vrV_j))), 
                 data=data,
                 start = list(e=0, vrA_j=1, vrV_j=1),
                 nls.control(warnOnly = TRUE)) 
}

##Fit the models for each subject

#Split data by subject 
data_by_subj_s <- split(sound_all_exp1, sound_all_exp1$ID) 
data_by_subj_c <- split(concept_all_exp1, concept_all_exp1$ID)
data_by_subj_j <- split(joint_all_exp1, joint_all_exp1$ID)

#.. and fit
model_by_subj_s <- map(data_by_subj_s, fit_s) 
model_by_subj_c <- map(data_by_subj_c, fit_c)
model_by_subj_j <- map(data_by_subj_j, fit_j)

```

Unimodal conditions
```{r}
## Generate model predictions to plot with human data in the unimodal conditions

x <- seq(0, 4, 0.01)

pred_s <- function(model, ID){
  y <- predict(model, list(sound_dist = x), type="response")
  data.frame(distance=x, prediction=y, ID=ID) 
}

pred_c <- function(model, ID){
  y <- predict(model, list(concept_dist = x), type="response")
  data.frame(distance=x, prediction=y, ID=ID) 
}

ID <- as.list(strsplit(names(model_by_subj_s), " "))

#Generate  predictions for each subject
pred_s <- map2(model_by_subj_s, ID, model_pred_s) %>%
  bind_rows()
pred_c <- map2(model_by_subj_c, ID, model_pred_c) %>%
  bind_rows()

##Plot

ggplot(sounds_exp1, 
       aes(x = distance, y = mean)) + 
  geom_point()+
  #geom_pointrange(aes(ymin = lower, ymax = upper), 
  #                position = position_dodge(width = .1), size = 0.4, fatten = 2) + 
  #geom_line(data=uniV,aes(x=xV, y=yV))+
  geom_line(data=pred_s, aes(x=distance, y=prediction), col='black')+
  #geom_line(data=uni_me_s, aes(x=distance, y=prediction), col='blue')+
  geom_line(data=pred_nl_s, aes(x=distance, y=prediction), col='red')+
  xlab("Distance") +ylab("Prob. different")+
  scale_y_continuous(limits = c(0, 1))+#theme(aspect.ratio = 0.7)+
  theme_few()+
  theme(aspect.ratio = 0.7) + facet_grid(. ~ ID)

ggplot(concepts_exp1, 
       aes(x = distance, y = mean)) + 
  geom_point()+
  #geom_pointrange(aes(ymin = lower, ymax = upper), 
  #                position = position_dodge(width = .1), size = 0.4, fatten = 2) + 
  #geom_line(data=uniV,aes(x=xV, y=yV))+
  geom_line(data=pred_c, aes(x=distance, y=prediction), col='black')+
  #geom_line(data=uni_me_s, aes(x=distance, y=prediction), col='blue')+
  geom_line(data=pred_nl_c, aes(x=distance, y=prediction), col='red')+
  xlab("Distance") +ylab("Prob. different")+
  scale_y_continuous(limits = c(0, 1))+#theme(aspect.ratio = 0.7)+
  theme_few()+
  theme(aspect.ratio = 0.7) + facet_grid(. ~ ID)

  
  

```

Here compute the optimal combination
```{r}

##Extract coefficients from unimodal condition to build the optimal model and compare to descriptive model

#Unimodal coefficients
 co_uni <- function(model, ID) {
   data.frame(bias=coefficients(model)[1], 
              variance=coefficients(model)[2], 
              ID=ID)
 }
 
 #Bimodal coefficients
 co_bim <- function(model, ID) {
   data.frame(bias=coefficients(model)[1],
              var_s=coefficients(model)[2],
              var_c=coefficients(model)[3],
              ID=ID)
 }

#Here extract ceofficients to build optimal model later
coef_s <- map2(model_by_subj_s, ID, co_uni) %>%
  bind_rows() %>%
  rename(vrA_u= variance,
         bA_u =  bias)

coef_c <- map2(model_by_subj_c, ID, co_uni) %>%
  bind_rows() %>%
  rename(vrV_u= variance,
         bV_u =  bias)

coef_j <- map2(model_by_subj_j, ID, co_bim) %>%
  bind_rows() %>%
  rename(vrA_j = var_s,
         vrV_j = var_c,  
         b =  bias)


## Below are functions that take sound and concept distances and return the predicted joint value in each model

# Sound only
model_s <- function (data, x,y) {
  vrA = unique(data$vrA_u)
  b = unique(data$bA_u)
  
  1/(1 + (1-b)*exp((-4/vrA)*x+(8/vrA)))
}

# Visual only
model_c <- function (data, x,y) {
  vrV = unique(data$vrV_u)
  b = unique(data$bV_u)
  
  1/(1 + (1-b)*exp((-4/vrV)*y+(8/vrV)))
}

# Optimal
model_opt <- function (data, x,y) {
  vrA = unique(data$vrA_u)
  vrV = unique(data$vrV_u)
  e   = unique(data$b)
  
  1/(1 + (1-e)*exp((-4/vrA)*x+(-4/vrV)*y+(8/vrA)+(8/vrV)))
}

# Descriptive
model_des <- function (data, x,y) {
  vrA = unique(data$vrA_j)
  vrV = unique(data$vrV_j)
  e   = unique(data$b)
  
  1/(1 + (1-e)*exp((-4/vrA)*x+(-4/vrV)*y+(8/vrA)+(8/vrV)))
}


data_models <- joint_exp1 %>%
  left_join(coef_s) %>%
  left_join(coef_c) %>%
  left_join(coef_j)
  

models <- function (subject_data) {
  subject_data %>% rename(Joint = mean) %>%
  mutate(Descriptive = model_des(subject_data, sound_dist, concept_dist)) %>%
  mutate(Optimal = model_opt(subject_data, sound_dist, concept_dist)) %>%
  mutate(Auditory = model_s(subject_data, sound_dist, concept_dist)) %>%
  mutate(Visual = model_c(subject_data, sound_dist, concept_dist)) %>%
  gather(model, pred, Visual, Auditory, Optimal, Descriptive) 
}

data_by_subj <- split(data_models, data_models$ID) 

data_preds <- map(data_by_subj, models) %>%
  bind_rows()

data_preds$model <- factor(data_preds$model, levels = c('Visual','Auditory', 'Optimal', 'Descriptive'))

correlations <- data_preds %>%
  group_by(ID, model) %>%
  summarise(cor = round(cor(Joint, pred), 2))

ggplot(data_preds, 
       aes(x = pred, y = Joint)) +
           #col = factor(concept_dist), 
          # shape = factor(sound_dist))) + 
  geom_point(size =1)+
  scale_colour_solarized()+
 #geom_pointrange(aes(ymin = summary_ci_lower, ymax = summary_ci_upper), 
  #                position = position_dodge(width = .1), size=0.2) + 
  geom_abline(slope = 1, lty = 2) +
  xlab("Predictions") +ylab("Human data")+
  facet_grid(ID ~ model)+
  theme_few()+
  geom_text(data=correlations, aes(label=paste("r=", cor, sep="")), x=0.5, y=0.95, size=2, fontface = "bold", col="red")+
theme(aspect.ratio = 0.7, 
      axis.text=element_text(size=6),
      strip.text.y = element_text(size = 8))+
  guides(color=guide_legend(title="Visual Distance")) +
  guides(shape=guide_legend(title="Auditory Distance")) 




```

```{r}



  
coef_s = tidy(fit_s, model) 
coef_nl_s = tidy(fit_nl_s, model)
#Posterior for visual-only condition
concept_nl1 <- nls(answer ~ 1/(1+(1-e)*exp((-4/vrV)*concept_dist+(8/vrV))), data=concept_all_exp1, start = list(e=0, vrV=2))

#Posterior for audio-visual condition (this is the descriptive model)
joint_nl1 <- nls(answer ~ 1/(1+(1-e)*exp((-4/vrA_j)*sound_dist+(-4/vrV_j)*concept_dist+(8/vrA_j)+(8/vrV_j))), data=joint_all_exp1, start = list(e=0, vrA_j=2, vrV_j=2))

##extract coefficient
eA_nl1 <- coef(sound_nl1)["e"]
vrA_nl1 <- coef(sound_nl1)["vrA"]

eV_nl1 <- coef(concept_nl1)["e"]
vrV_nl1 <- coef(concept_nl1)["vrV"]

eJ_nl1 <- coef(joint_nl1)["e"]
vrJ_A_nl1 <- coef(joint_nl1)["vrA_j"]
vrJ_V_nl1 <- coef(joint_nl1)["vrV_j"]
#######

### the fit functions
x <- seq(0, 4, 0.01)

y_sound_nl1 <- predict(sound_nl1, list(sound_dist = x), type="response")
y_concept_nl1 <- predict(concept_nl1, list(concept_dist = x), type="response")

uniS_nl1 <- data.frame(distance=x, prediction=y_sound_nl1) %>%
  mutate(Condition = 'Auditory', 
         Experiment ='Experiment 1')

uniV_nl1 <- data.frame(distance=x, prediction=y_concept_nl1) %>%
  mutate(Condition = 'Visual',
         Experiment ='Experiment 1')

```

Fit individual curves
```{r}
#Increase the number of unimodal (since this is where the models do not converge) and decrease the number of joint, to 

#Sound Unimodal
fit_s <- sound_all_exp1 %>%
  group_by(ID) %>%
  do(model = glm(answer ~  sound_dist, 
                 data=., 
                 family = binomial())) 

fit_nl_s <- sound_all_exp1 %>%
  group_by(ID) %>%
  do(model = nls(answer ~ 1/(1+(1-e)*exp((-4/vrA)*sound_dist+(8/vrA))), 
                 data=.,
                 start = list(e=0, vrA=1),
                 nls.control(warnOnly = TRUE))) 

coef_s = tidy(fit_s, model) 
coef_nl_s = tidy(fit_nl_s, model)

#Concept Unimodal
fit_c <- concept_all_exp1 %>%
  group_by(ID) %>%
  do(model = glm(answer ~  concept_dist, 
                 data=., 
                 family = binomial())) 

fit_nl_c <- concept_all_exp1 %>%
  group_by(ID) %>%
  do(model = nls(answer ~ 1/(1+(1-e)*exp((-4/vrV)*concept_dist+(8/vrV))), 
                 data=.,
                 start = list(e=0, vrV=1),
                 nls.control(warnOnly = TRUE))) 

coef_c = tidy(fit_c, model) 
coef_nl_c = tidy(fit_nl_c, model)

x <- seq(0, 4, 0.01)

#This simulation is not working!
simul <- fit_s %>%
  rowwise() %>%
  do(sim = predict(model, list(sound_dist = x), type="response"))


#Joint 
fit_j <- joint_all_exp1 %>%
  group_by(ID) %>%
  do(model = glm(answer ~  sound_dist + concept_dist, 
                 data=., 
                 family = binomial())) 

fit_nl_j <- joint_all_exp1 %>%
  group_by(ID) %>%
  do(model = nls(answer ~ 1/(1+(1-e)*exp((-4/vrA_j)*sound_dist+(-4/vrV_j)*concept_dist+(8/vrA_j)+(8/vrV_j))),
                 data=.,
                 start = list(e=0, vrA_j=2, vrV_j=2),
                 nls.control(warnOnly = TRUE)))

coef_j = tidy(fit_j, model) 
coef_nl_j = tidy(fit_nl_j, model)


#2 steps:
#1) Do the full model with Subjects as random effect 
#2) Show the distribution of cue integration at the individual level (instead of just the joint model); that is, computet the proportion of 1) the weighing of the indivisual model (V/S)_uni to th weighing of the  

##extract coefficient
eA_nl1 <- coef(sound_nl1)["e"]
vrA_nl1 <- coef(sound_nl1)["vrA"]

eV_nl1 <- coef(concept_nl1)["e"]
vrV_nl1 <- coef(concept_nl1)["vrV"]

eJ_nl1 <- coef(joint_nl1)["e"]
vrJ_A_nl1 <- coef(joint_nl1)["vrA_j"]
vrJ_V_nl1 <- coef(joint_nl1)["vrV_j"]
#######

### the fit functions
x <- seq(0, 4, 0.01)

y_sound_nl1 <- predict(sound_nl1, list(sound_dist = x), type="response")
y_concept_nl1 <- predict(concept_nl1, list(concept_dist = x), type="response")

uniS_nl1 <- data.frame(distance=x, prediction=y_sound_nl1) %>%
  mutate(Condition = 'Auditory', 
         Experiment ='Experiment 1')

uniV_nl1 <- data.frame(distance=x, prediction=y_concept_nl1) %>%
  mutate(Condition = 'Visual',
         Experiment ='Experiment 1')

```

Plots
```{r}
ggplot(exp_uni_data, 
       aes(x = distance, y = mean)) + 
  geom_point()+
  geom_pointrange(aes(ymin = lower, ymax = upper), 
                  position = position_dodge(width = .1), size = 0.4, fatten = 2) + 
  #geom_line(data=uniV,aes(x=xV, y=yV))+
  #geom_line(data=all_uni_model, aes(x=distance, y=prediction), col='black')+
  xlab("Distance") +ylab("Prob. different")+
  #scale_y_continuous(limits = c(0, 1))+#theme(aspect.ratio = 0.7)+
  theme_few()+
  theme(aspect.ratio = 0.7) + facet_grid(ID ~ Condition)
  #stat_function(fun = Logistic_v, colour="red"))

```


Fit the models.
```{r}

#Fit the uniomodal sound condition
sound_data <- d %>%
    filter(condition == "sound")

concept_data <- d %>%
    filter(condition == "concept")

joint_data <- d %>%
    filter(condition == "joint")

#Fit the uniomodal sound condition with a logistic regression
fit_sound <- glm(answer ~ sound_dist, data=sound_data, family = binomial())

##extract coefficient
s_coef <- coef(fit_sound)["sound_dist"]
s_inter <- coef(fit_sound)["(Intercept)"]

#prameters of the sound distribution
s_var=4/(s_coef)
s_sum=-1*s_inter/s_coef

#Fit the uniomodal visual conditon
fit_concept <- glm(answer ~ concept_dist, data=concept_data, family = binomial())

##extract coefficient
c_coef <- coef(fit_concept)["concept_dist"]
c_inter <- coef(fit_concept)["(Intercept)"]

#prameters of the sound distribution
v_var=4/(c_coef)
v_sum=-1*c_inter/c_coef

#Fit the bimodal conditon
fit_joint <- glm(answer ~ sound_dist+concept_dist, data=joint_data, family = binomial())

##extract coefficient
j_coef_a <- coef(fit_joint)["sound_dist"]
j_coef_v <- coef(fit_joint)["concept_dist"]
j_inter <- coef(fit_joint)["(Intercept)"]

#prameters of the sound distribution (approx: the average mean sum equal to 0+4/2=2)
j_var_a=4/(j_coef_a)
j_var_v=4/(j_coef_v)

#decision_ideal=v_va/s_va

#decision_fit=j_va_v/j_va_s

# preference = decision_fit/decision_ideal

```


Analysis of the unimodal cases.
```{r}

#Recogniton functions from the unimodal fit 
x <- seq(0, 4, 0.01)

y_sound <- predict(fit_sound, list(sound_dist = x), type="response")
y_concept <- predict(fit_concept, list(concept_dist = x), type="response")

uniS <- data.frame(xS=x,yS=y_sound)
uniV <- data.frame(xV=x,yV=y_concept)

#Recognition functions from the bimodal fit (marginal distributions)
Logistic_a = function (x, A = j_coef_a , B = 2*j_coef_a) {
    1 / (1 + exp(-1*(-B +A * x)))
}

Logistic_v = function (x, A = j_coef_v , B = 2*j_coef_v) {
    1 / (1 + exp(-1*(-B +A * x)))
}

#Plot all these functions in the same graph

##The auditory case
ggplot(sounds, 
       aes(x = sound_dist, y = mean)) + 
  geom_pointrange(aes(ymin = summary_ci_lower, ymax = summary_ci_upper), 
                  position = position_dodge(width = .1)) + 
  geom_line(data=uniS,aes(x=xS, y=yS))+
  xlab("Auditory distance") +ylab("% different")+
  scale_y_continuous(limits = c(0, 1))+
  stat_function(fun = Logistic_a, colour="red")

##The visual case
ggplot(concepts, 
       aes(x = concept_dist, y = mean)) + 
  geom_pointrange(aes(ymin = summary_ci_lower, ymax = summary_ci_upper), 
                  position = position_dodge(width = .1)) + 
  geom_line(data=uniV,aes(x=xV, y=yV))+
  xlab("Visual distance") +ylab("% different")+
  scale_y_continuous(limits = c(0, 1))+
  stat_function(fun = Logistic_v, colour="red")
 

```
Individual analysis:

```{r}

#Fit the uniomodal sound condition

d <- d1

sound_bysub <- d %>%
  filter(condition == "sound") %>%
  group_by(ID) %>%
  do(fit_sound = glm(answer ~ sound_dist, data=., family = binomial()))

soundCoef = tidy(sound_bysub, fit_sound) %>%
  filter(term == 'sound_dist') %>%
  mutate(s_var = 4/(estimate)) %>%
  select(ID, s_var)

concept_bysub <- d %>%
  filter(condition == "concept") %>%
  group_by(ID) %>%
  do(fit_concept = glm(answer ~ concept_dist, data=., family = binomial()))

conceptCoef = tidy(concept_bysub, fit_concept) %>%
  filter(term == 'concept_dist') %>%
  mutate(c_var = 4/(estimate)) %>%
  select(ID, c_var)

unimodal_bysub <- soundCoef %>%
  left_join(conceptCoef) %>%
  mutate(unim = c_var/s_var)


joint_bysub <- d %>%
  filter(condition == "joint") %>%
  group_by(ID) %>%
  do(fit_joint = glm(answer ~ concept_dist+ sound_dist, data=., family = binomial()))


bimodal_bysub = tidy(joint_bysub, fit_joint) %>%
  filter(term == 'concept_dist' | term == 'sound_dist') %>%
  mutate(j_var = 4/(estimate)) %>%
  select(ID, term, j_var) %>%
  spread(term, j_var) %>%
  rename(j_c_var = concept_dist, 
         j_s_var = sound_dist) %>%
  mutate(bimod = j_c_var/j_s_var)
  
all_bysub <- unimodal_bysub  %>%
  left_join(bimodal_bysub) %>%
  mutate(ideal = bimod/unim)




```
```{r}
ggplot(data=all_bysub, aes(s_var)) + 
  geom_vline(xintercept=1, col='red')+
  geom_histogram(binwidth = 0.4) +
  xlim(-15,15)

ggplot(data=all_bysub, aes(c_var)) + 
  geom_vline(xintercept=1, col='red')+
  geom_histogram(binwidth = 0.4) +
  xlim(-15,15)

ggplot(data=all_bysub, aes(unim)) + 
  geom_vline(xintercept=1, col='red')+
  geom_histogram(binwidth = 0.4) +
  xlim(-15,15)

ggplot(data=all_bysub, aes(j_s_var)) + 
  geom_vline(xintercept=1, col='red')+
  geom_histogram(binwidth = 0.4) +
  xlim(-15,15)

ggplot(data=all_bysub, aes(j_c_var)) + 
  geom_vline(xintercept=1, col='red')+
  geom_histogram(binwidth = 0.4) +
  xlim(-15,15)

ggplot(data=all_bysub, aes(bimod)) + 
  geom_vline(xintercept=1, col='red')+
  geom_histogram(binwidth = 0.4) +
  xlim(-11,11)+
  scale_x_log10()


```


```{r}
neg_N <- bimodal_bysub %>%
  filter(bimod <  -0.1) %>%
  filter(bimod > -10) 


joint_sub <- joint_all_exp1 %>%
  filter(ID == 'subject_13') %>%
  group_by(concept_dist, sound_dist) %>%
  multi_boot_standard(col = "answer")
```

```{r}
ggplot(joint_sub, 
       aes(x = concept_dist, y = mean, col = factor(sound_dist))) + 
  geom_line(lty = 2) + 
  xlab("Auditory distance") +ylab("% different")+
  scale_colour_discrete(name="Visual Dist")+
theme(legend.title = element_text(size=8))

```


The bimodal case
```{r}

# Bimodal recognition functions

##the bimodal fit 
model_fit <- function (x,y) {
   1/(1 + exp(-x*j_coef_a-y*j_coef_v+2*j_coef_a+2*j_coef_v))
}

##Values of the baseline
model_base <- function (x,y) {
   1/(1 + exp(-x*s_coef-y*c_coef+2*s_coef+2*c_coef))
}

# Add the fit the baeline to data

ms_all <- joint %>% 
  rename(joint = mean) %>%
  left_join(select(concepts, concept_dist, mean) %>% 
              rename(concepts = mean)) %>%
  left_join(select(sounds, sound_dist, mean) %>% 
              rename(sounds = mean)) %>%
  mutate(fit = model_fit(sound_dist, concept_dist)) %>%
  mutate(base = model_base(sound_dist, concept_dist)) %>%
  gather(model, pred, concepts, sounds, base, fit)

#Plot Heat map for the data
ggplot(data = ms_all, aes(x=sound_dist, y=concept_dist, fill=joint)) + 
  geom_tile()+scale_fill_continuous(limits=c(0, 1))+xlab("Auditory distance") +ylab("Visual distance")


#Plot Heatmap for the baseline
mybase <- ms_all %>%
  filter(model=="base")

ggplot(data = mybase, aes(x=sound_dist, y=concept_dist, fill=pred)) + 
  geom_tile()+scale_fill_continuous(limits=c(0, 1))+xlab("Auditory distance") +ylab("Visual distance")

myfilter <- ms_all %>%
  filter(model=="fit" | model=="base")

#Correlation models (baseline and fit) to bimodal data 
ggplot(myfilter, 
       aes(x = pred, y = joint, col = factor(concept_dist), 
           shape = factor(sound_dist))) +
 geom_pointrange(aes(ymin = ci_lower, ymax = ci_upper), 
                  position = position_dodge(width = .1)) + 
  geom_abline(slope = 1, lty = 2) +
  facet_grid(model~.)



```

The modality dominance
```{r}

#Modality dominance coeficent
a_fit=2
a_base=1
a_Vdom=2*a_base
a_Sdom=0.5*a_base

s_var=1
v_var=1
j_var_a=2
j_var_v=2

#Classification thresholds (prob=0.5) for:

##The basline (combination of the unimodal cases)
classif_base = function (x, A=a_base) {
    2*(A+1)-A*x
}

##Best bivariate fit 
classif_fit = function (x, A=a_fit) {
    2*(A+1)-A*x
}

##A baseline for visual domiance
classif_Vdom = function (x, A=a_Vdom) {
    2*(A+1)-A*x
}

##A baseline for auditory domiance
classif_Sdom = function (x, A=a_Sdom) {
    2*(A+1)-A*x
}

#Sample from the baseline bivariate distribution
Gaus_base <- data.frame(x=c(rnorm(1000,0,sqrt(s_var)),rnorm(1000,4,sqrt(s_var))),
          y=c(rnorm(1000,0,sqrt(v_var)),rnorm(1000,4,sqrt(v_var))))

#Plot samples from the bivariate distribution
ggplot(Gaus_base, aes(x,y)) +  stat_density2d(geom="contour",aes(alpha=..level..))+
  scale_alpha_continuous(limits=c(0,0.03),breaks=1e-6*seq(0,10,by=2))+
  stat_function(fun = classif_base, colour = "red") +xlab("Auditory") +ylab("Visual")+ scale_x_continuous(limits = c(-6, 10))+scale_y_continuous(limits = c(-6, 10))

#Sample from the best bivariate fit 
Gaus_fit <- data.frame(x=c(rnorm(1000,0,sqrt(j_var_a)),rnorm(1000,4,sqrt(j_var_a))),
          y=c(rnorm(1000,0,sqrt(j_var_v)),rnorm(1000,4,sqrt(j_var_v))))

#Plot samples from the best bivariate fit
ggplot(Gaus_fit, aes(x,y)) +  stat_density2d(geom="contour",aes(alpha=..level..))+
  scale_alpha_continuous(limits=c(0,0.03),breaks=1e-6*seq(0,10,by=2))+
  stat_function(fun = classif_fit, colour = "red") +xlab("Auditory") +ylab("Visual") + scale_x_continuous(limits = c(-6, 10))+scale_y_continuous(limits = c(-6, 10))

#Modality dominance?
ggplot(Gaus_fit, aes(x,y)) +
  stat_function(fun = classif_base, colour = "red", lty=2) +
  stat_function(fun = classif_Vdom, colour = "blue", lty=2 )+
  stat_function(fun = classif_Sdom, colour = "blue", lty=2)+
  stat_function(fun = classif_fit, colour = "black")+
  xlab("Auditory") +ylab("Visual") + scale_x_continuous(limits = c(-6, 10))+
  scale_y_continuous(limits = c(-6, 10))+theme(aspect.ratio = 1)

```








