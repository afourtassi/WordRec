---
title: "WordRec Experiment"
author: "A. Fourtassi"
date: "November 26, 2018"
output:
  html_document:
    number_sections: yes
    toc: yes
---
Libraries.

```{r}
#library(papaja)
library(broom)
  library(purrr)
  library(readr)
  library(ggplot2)
  library(dplyr)
  library(tidyr)
  #library(wordbankr)
  library(stringr)
  library(feather)
  library(lme4)
  library(boot)
  library(langcog)
  library(ggthemes)
  library(nlme)
  #library(rwebppl)
  library(jsonlite)
  library(Hmisc)
  library(poweRlaw)
  library(HDInterval)
  #library(kableExtra)
```

Data and processing
```{r}

##We will collect N=50 participants, and the data will be processed as follows

exp1 <- read_delim("data_rev_real1.txt", delim = " ") %>%
  filter(type == "Task") %>%
  mutate(experiment='Experiment1')

N_all_1 <- exp1 %>%
  distinct(ID) %>%
  nrow()
  
exp1_noProb <- exp1 %>%
  filter(problem=="No") 

N_noProb_1 <- exp1_noProb %>%
  distinct(ID) %>%
  nrow()

exp1_good <- exp1_noProb %>%
  filter(score >= 0.75)

N_good_1 <- exp1_good %>%
  distinct(ID) %>%
  nrow()

sound_all_exp1 <- exp1_good %>%
    filter(condition == "sound")

concept_all_exp1 <- exp1_good %>%
    filter(condition == "concept")

joint_all_exp1 <- exp1_good %>%
    filter(condition == "joint")


```

Fit the aggregate  data,

This a replcition of the unimodal data with aggregated data
```{r}
data_s <- sound_all_exp1 %>%
  group_by(sound_dist) %>%
  dplyr::summarise(mean = mean(answer),
                   sd = sd(answer),
                   n = n()) %>%
  mutate(se = sd / sqrt(n),
         lower = mean - qt(1 - (0.05 / 2), n - 1) * se,
         upper = mean + qt(1 - (0.05 / 2), n - 1) * se) %>%
  select(-sd, -n, -se,) %>%
  mutate(Experiment="Experiment 1", 
         Condition="Auditory") %>%
  rename(distance = sound_dist)

data_c <- concept_all_exp1 %>%
  group_by(concept_dist) %>%
  dplyr::summarise(mean = mean(answer),
                   sd = sd(answer),
                   n = n()) %>%
  mutate(se = sd / sqrt(n),
         lower = mean - qt(1 - (0.05 / 2), n - 1) * se,
         upper = mean + qt(1 - (0.05 / 2), n - 1) * se) %>%
  select(-sd, -n, -se,) %>%
  mutate(Experiment="Experiment 1", 
         Condition="Visual") %>%
  rename(distance = concept_dist)

data_j <- joint_all_exp1 %>%
  group_by(sound_dist, concept_dist) %>%
  dplyr::summarise(mean = mean(answer),
                   sd = sd(answer),
                   n = n()) %>%
  mutate(se = sd / sqrt(n),
         lower = mean - qt(1 - (0.05 / 2), n - 1) * se,
         upper = mean + qt(1 - (0.05 / 2), n - 1) * se) %>%
  select(-sd, -n, -se,) %>%
  mutate(Experiment="Experiment 1", 
         Condition="Joint") 

data_all <- bind_rows(data_s, data_c)

model_s <- nls(answer ~ 1/(1+(1-e)*exp((-4/vrA)*sound_dist+(8/vrA))), data=sound_all_exp1, start = list(e=0, vrA=2))
model_c <- nls(answer ~ 1/(1+(1-e)*exp((-4/vrV)*concept_dist+(8/vrV))), data=concept_all_exp1, start = list(e=0, vrV=2))
model_j <- nls(answer ~ 1/(1+(1-e)*exp((-4/vrA_j)*sound_dist+(-4/vrV_j)*concept_dist+(8/vrA_j)+(8/vrV_j))), data=joint_all_exp1, start = list(e=0, vrA_j=2, vrV_j=2))

#Plot the data here
x <- seq(0, 4, 0.01)

y_s <- predict(model_s, list(sound_dist = x), type="response")
y_c <- predict(model_c, list(concept_dist = x), type="response")

pred_all <- bind_rows(data.frame(distance=x, prediction=y_s, Condition = "Auditory"), 
                      data.frame(distance=x, prediction=y_c, Condition = "Visual")) 
  
#Derive values of the variance from the 
ggplot(data_all, 
       aes(x = distance, y = mean)) + 
  geom_point()+
  geom_pointrange(aes(ymin = lower, ymax = upper), 
                  position = position_dodge(width = .1), size = 0.4, fatten = 2) + 
  #geom_line(data=uniV,aes(x=xV, y=yV))+
  geom_line(data=pred_all, aes(x=distance, y=prediction), col='black')+
  #geom_line(data=uni_me_s, aes(x=distance, y=prediction), col='blue')+
  #geom_line(data=uni_nl_s, aes(x=distance, y=prediction), col='red')+
  xlab("Distance") +ylab("Prob. different")+
  scale_y_continuous(limits = c(0, 1))+#theme(aspect.ratio = 0.7)+
  theme_few()+
  theme(aspect.ratio = 0.7) + facet_grid(. ~ Condition)


```
Optimal model

This is a replication of the optimality analysis for aggregated data 

```{r}
#Extract cefficieny

eA <- coefficients(model_s)["e"]
vrA <- coefficients(model_s)["vrA"]

eV <- coefficients(model_c)["e"]
vrV <- coefficients(model_c)["vrV"]

ej <- coefficients(model_j)["e"]
vrAj <- coefficients(model_j)["vrA_j"]
vrVj <- coefficients(model_j)["vrV_j"]

#The sound-only model
m_s <- function (x,y) {
  1/(1 + (1-eA)*exp((-4/vrA)*x+(8/vrA)))
}

#The visual-only model
m_c <- function (x,y) {
  1/(1 + (1-eV)*exp((-4/vrV)*y+(8/vrV)))
}

#Descriptive model (parameters are derived from fit to bimodal data)
m_opt <- function (x,y) {
   1/(1 + (1-ej)*exp((-4/vrA)*x+(-4/vrV)*y+(8/vrA)+(8/vrV)))
}

#The optimal model (parameters are derived from fit to unimodal data)
m_des <- function (x,y) {
    1/(1 + (1-ej)*exp((-4/vrAj)*x+(-4/vrVj)*y+(8/vrAj)+(8/vrVj)))
}

pred_all_comb <- data_j %>% 
  rename(joint = mean) %>%
  mutate(Descriptive = m_des(sound_dist, concept_dist)) %>%
  mutate(Optimal = m_opt(sound_dist, concept_dist)) %>%
  mutate(Auditory = m_s(sound_dist, concept_dist)) %>%
  mutate(Visual = m_c(sound_dist, concept_dist)) %>%
  gather(model, pred, Visual, Auditory, Optimal, Descriptive) %>%
  mutate(experiment = 'Experiment 1')


pred_all_comb$model <- factor(pred_all_comb$model, levels = c('Visual','Auditory', 'Optimal', 'Descriptive'))

correlations <- pred_all_comb %>%
  group_by(model) %>%
  summarise(cor = round(cor(joint, pred), 2))

ggplot(pred_all_comb, 
       aes(x = pred, y = joint)) +
           #col = factor(concept_dist), 
          # shape = factor(sound_dist))) + 
  geom_point(size =1)+
  scale_colour_solarized()+
 #geom_pointrange(aes(ymin = summary_ci_lower, ymax = summary_ci_upper), 
  #                position = position_dodge(width = .1), size=0.2) + 
  geom_abline(slope = 1, lty = 2) +
  xlab("Predictions") +ylab("Human data")+
  facet_grid(. ~ model)+
  theme_few()+
  geom_text(data=correlations, aes(label=paste("r=", cor, sep="")), x=0.5, y=0.95, size=2, fontface = "bold", col="red")+
theme(aspect.ratio = 0.7, 
      axis.text=element_text(size=6),
      strip.text.y = element_text(size = 8))+
  guides(color=guide_legend(title="Visual Distance")) +
  guides(shape=guide_legend(title="Auditory Distance")) 






```

Human data by subject
```{r}

sounds_exp1 <- exp1_good %>%
  filter(condition == "sound") %>%
  group_by(ID, sound_dist) %>%
  dplyr::summarise(mean = mean(answer),
                   sd = sd(answer),
                   n = n()) %>%
  mutate(se = sd / sqrt(n),
         lower = mean - qt(1 - (0.05 / 2), n - 1) * se,
         upper = mean + qt(1 - (0.05 / 2), n - 1) * se) %>%
  select(-sd, -n, -se,) %>%
  mutate(Experiment="Experiment 1", 
         Condition="Auditory") %>%
  rename(distance = sound_dist)

concepts_exp1 <- exp1_good %>%
  filter(condition == "concept") %>%
  group_by(ID, concept_dist) %>%
  dplyr::summarise(mean = mean(answer),
                   sd = sd(answer),
                   n = n()) %>%
  mutate(se = sd / sqrt(n),
         lower = mean - qt(1 - (0.05 / 2), n - 1) * se,
         upper = mean + qt(1 - (0.05 / 2), n - 1) * se) %>%
  select(-sd, -n, -se,) %>%
  mutate(Experiment="Experiment 1", 
         Condition="Visual") %>%
  rename(distance = concept_dist)


joint_exp1 <- exp1_good %>%
  filter(condition == "joint") %>%
  group_by(ID, concept_dist, sound_dist) %>%
  summarise(mean = mean(answer)) %>%
  mutate(Experiment="Experiment 1", 
         Condition="Joint")


exp_uni_data <- bind_rows(sounds_exp1, concepts_exp1)
```

Here fit a different model for every subject
There are probably convergence issues with some participants, should check this later
(I think I should take those out of the analysis)
```{r}

#Models 

#Sound Unimodal
fit_s <- function(data) {
  nls(answer ~ 1/(1+(1-e)*exp((-4/vrA)*sound_dist+(8/vrA))), 
                 data=data,
                 start = list(e=0, vrA=1),
                 nls.control(warnOnly = TRUE)) 
}
#Concept Unimodal
fit_c <- function(data) {
  nls(answer ~ 1/(1+(1-e)*exp((-4/vrV)*concept_dist+(8/vrV))), 
                 data=data,
                 start = list(e=0, vrV=1),
                 nls.control(warnOnly = TRUE)) 
}

#Joint sound-concept
fit_j <- function(data) {
  nls(answer ~1/(1+(1-e)*exp((-4/vrA_j)*sound_dist+(-4/vrV_j)*concept_dist+(8/vrA_j)+(8/vrV_j))), 
                 data=data,
                 start = list(e=0, vrA_j=1, vrV_j=1),
                 nls.control(warnOnly = TRUE)) 
}

##Fit the models for each subject

#Split data by subject 
data_by_subj_s <- split(sound_all_exp1, sound_all_exp1$ID) 
data_by_subj_c <- split(concept_all_exp1, concept_all_exp1$ID)
data_by_subj_j <- split(joint_all_exp1, joint_all_exp1$ID)

#.. and fit
model_by_subj_s <- map(data_by_subj_s, fit_s) 
model_by_subj_c <- map(data_by_subj_c, fit_c)
model_by_subj_j <- map(data_by_subj_j, fit_j)

```

How to plot this? (but this visualization is not crucial)
Plot for every condition? or just change color for every participant (maybe too much to parse)
PLot just the means and ci?

```{r}
## Generate model predictions to plot with human data in the unimodal conditions

x <- seq(0, 4, 0.01)

pred_s <- function(model, ID){
  y <- predict(model, list(sound_dist = x), type="response")
  data.frame(distance=x, prediction=y, ID=ID) 
}

pred_c <- function(model, ID){
  y <- predict(model, list(concept_dist = x), type="response")
  data.frame(distance=x, prediction=y, ID=ID) 
}

ID <- as.list(strsplit(names(model_by_subj_s), " "))

#Generate  predictions for each subject
pred_s <- map2(model_by_subj_s, ID, model_pred_s) %>%
  bind_rows()
pred_c <- map2(model_by_subj_c, ID, model_pred_c) %>%
  bind_rows()

##Plot

ggplot(sounds_exp1, 
       aes(x = distance, y = mean, group = distance)) + 
  geom_boxplot()+
  #geom_line()+
  #geom_smooth()+
  #geom_pointrange(aes(ymin = lower, ymax = upper), 
  #                position = position_dodge(width = .1), size = 0.4, fatten = 2) + 
  #geom_line(data=uniV,aes(x=xV, y=yV))+
  geom_smooth(data=pred_s, aes(x=distance, y=prediction), col='black')+
  xlab("Distance") +ylab("Prob. different")+
  scale_y_continuous(limits = c(0, 1))+#theme(aspect.ratio = 0.7)+
  theme_few()+
  theme(aspect.ratio = 0.7) #+ facet_grid(. ~ ID)

ggplot(subset(concepts_exp1, ID=="subject_1"), 
       aes(x = distance, y = mean, col = ID)) + 
  geom_point()+
  #geom_pointrange(aes(ymin = lower, ymax = upper), 
  #                position = position_dodge(width = .1), size = 0.4, fatten = 2) + 
  #geom_line(data=uniV,aes(x=xV, y=yV))+
  geom_line(data=subset(pred_c,ID=="subject_1"), aes(x=distance, y=prediction), col='black')+
  xlab("Distance") +ylab("Prob. different")+
  scale_y_continuous(limits = c(0, 1))+#theme(aspect.ratio = 0.7)+
  theme_few()+
  theme(aspect.ratio = 0.7) #+ facet_grid(. ~ ID)


```
Here compute the cue combination analysis for each participant
```{r}

##Extract coefficients from unimodal condition to build the optimal model and compare to descriptive model

#Unimodal coefficients
 co_uni <- function(model, ID) {
   data.frame(bias=coefficients(model)[1], 
              variance=coefficients(model)[2], 
              ID=ID)
 }
 
 #Bimodal coefficients
 co_bim <- function(model, ID) {
   data.frame(bias=coefficients(model)[1],
              var_s=coefficients(model)[2],
              var_c=coefficients(model)[3],
              ID=ID)
 }

#Here extract ceofficients to build optimal model later
coef_s <- map2(model_by_subj_s, ID, co_uni) %>%
  bind_rows() %>%
  rename(vrA_u= variance,
         bA_u =  bias)

coef_c <- map2(model_by_subj_c, ID, co_uni) %>%
  bind_rows() %>%
  rename(vrV_u= variance,
         bV_u =  bias)

coef_j <- map2(model_by_subj_j, ID, co_bim) %>%
  bind_rows() %>%
  rename(vrA_j = var_s,
         vrV_j = var_c,  
         b =  bias)


## Below are functions that take sound and concept distances and return the predicted joint value in each model

# Sound only
model_s <- function (data, x,y) {
  vrA = unique(data$vrA_u)
  b = unique(data$bA_u)
  
  1/(1 + (1-b)*exp((-4/vrA)*x+(8/vrA)))
}

# Visual only
model_c <- function (data, x,y) {
  vrV = unique(data$vrV_u)
  b = unique(data$bV_u)
  
  1/(1 + (1-b)*exp((-4/vrV)*y+(8/vrV)))
}

# Optimal
model_opt <- function (data, x,y) {
  vrA = unique(data$vrA_u)
  vrV = unique(data$vrV_u)
  e   = unique(data$b)
  
  1/(1 + (1-e)*exp((-4/vrA)*x+(-4/vrV)*y+(8/vrA)+(8/vrV)))
}

# Descriptive
model_des <- function (data, x,y) {
  vrA = unique(data$vrA_j)
  vrV = unique(data$vrV_j)
  e   = unique(data$b)
  
  1/(1 + (1-e)*exp((-4/vrA)*x+(-4/vrV)*y+(8/vrA)+(8/vrV)))
}


data_models <- joint_exp1 %>%
  left_join(coef_s) %>%
  left_join(coef_c) %>%
  left_join(coef_j)
  

models <- function (subject_data) {
  subject_data %>% rename(Joint = mean) %>%
  mutate(Descriptive = model_des(subject_data, sound_dist, concept_dist)) %>%
  mutate(Optimal = model_opt(subject_data, sound_dist, concept_dist)) %>%
  mutate(Auditory = model_s(subject_data, sound_dist, concept_dist)) %>%
  mutate(Visual = model_c(subject_data, sound_dist, concept_dist)) %>%
  gather(model, pred, Visual, Auditory, Optimal, Descriptive) 
}

data_by_subj <- split(data_models, data_models$ID) 

data_preds <- map(data_by_subj, models) %>%
  bind_rows()

data_preds$model <- factor(data_preds$model, levels = c('Visual','Auditory', 'Optimal', 'Descriptive'))

correlations <- data_preds %>%
  group_by(ID, model) %>%
  summarise(cor = round(cor(Joint, pred), 2))

```

Plot by subject, not sure how to do it 
```{r}
ggplot(data_preds, 
       aes(x = pred, y = Joint)) +
           #col = factor(concept_dist), 
          # shape = factor(sound_dist))) + 
  geom_point(size =1)+
  scale_colour_solarized()+
 #geom_pointrange(aes(ymin = summary_ci_lower, ymax = summary_ci_upper), 
  #                position = position_dodge(width = .1), size=0.2) + 
  geom_abline(slope = 1, lty = 2) +
  xlab("Predictions") +ylab("Human data")+
  facet_grid(ID ~ model)+
  theme_few()+
  geom_text(data=correlations, aes(label=paste("r=", cor, sep="")), x=0.5, y=0.95, size=2, fontface = "bold", col="red")+
theme(aspect.ratio = 0.7, 
      axis.text=element_text(size=6),
      strip.text.y = element_text(size = 8))+
  guides(color=guide_legend(title="Visual Distance")) +
  guides(shape=guide_legend(title="Auditory Distance")) 


```

```{r}
#Make hitogram of optimality

histo_all <- correlations %>%
  group_by(ID) %>%
  filter(cor == max(cor)) %>%
  arrange(ID, model, cor)

histo_norm <- correlations %>%
  filter(model != 'Descriptive') %>%
  group_by(ID) %>%
  filter(cor == max(cor)) %>%
  arrange(ID, model, cor)

ggplot(histo_all, 
      aes(x = model)) +
  stat_count(width = 0.5)+
  #geom_histogram()+
  #scale_x_log10() +
  theme_few() + 
  theme(aspect.ratio = 0.7, legend.title = element_text(size=8)) +#  facet_grid(Segmentation ~ language)+
  #scale_y_continuous(labels = scales::percent)+
  xlab("Model") +ylab("Count")

ggplot(histo_norm, 
      aes(x = model)) +
  stat_count(width = 0.5)+
  #geom_histogram()+
  #scale_x_log10() +
  theme_few() + 
  theme(aspect.ratio = 0.7, legend.title = element_text(size=8)) +#  facet_grid(Segmentation ~ language)+
  #scale_y_continuous(labels = scales::percent)+
  xlab("Model") +ylab("Count")


```
Here I calculate the reliance on visual vs. auditory 

```{r}

weight <- data_models %>%
  group_by(ID, vrA_u, vrV_u, vrA_j, vrV_j) %>%
  select(ID, vrA_u, vrV_u, vrA_j, vrV_j) %>%
  unique() %>%
  mutate(weight_u = vrA_u/vrV_u,
         weight_b = vrA_j/vrV_j) %>%
  mutate(prop = weight_u/weight_b) 

weight_sum <- weight %>% 
  mutate(temp = 'temp') %>%
  group_by(temp) %>%
  multi_boot_standard(col = "prop")
  

weight_separate <- weight %>%
  select(ID, weight_u, weight_b) %>%
  gather (key, value, weight_u, weight_b)

weight.boot <- boot(data=weight$prop, function(x,i) median(x[i]), R=10000)

weight.ci=boot.ci(weight.boot, 
                  conf = 0.95,
                  type = c('perc'))


#weights.dist <- weight$prop[weight$prop < 100 & weight$prop > 0.01]

weight.median <- weight.ci$t0
weight.median_low <- weight.ci$percent[4]
weight.median_up <- weight.ci$percent[5]


ggplot(data=weight, aes(x=prop, y=..count..)) +
  geom_histogram(alpha=0.5, binwidth = 0.4)+
  geom_vline(xintercept = weight.median, col='red')+
  geom_vline(xintercept = weight.median_low, linetype='dashed') +
  geom_vline(xintercept = weight.median_up, linetype='dashed') +
  #geom_histogram(data=subset(bimod_all, data=='simulation'), fill="blue", alpha=0.2, binwidth = 0.2)+
  #geom_histogram(binwidth = 0.2) +
 scale_x_log10(breaks =c(0.1,1,10)) +
   xlab("Optimal weighing relative to real weighing") +ylab("Count")+
  theme_few()+
  theme(aspect.ratio = 0.7) +
  coord_cartesian(xlim=c(0.01,100))







```
I should do a test whether the variance is due to measurement noise or to geniune between-subject variability 
I should do the writing to see how these things will be intgrated
Here do the modality preference test (the same analysis I did for the aggragated data)

HERE
Old indivudual analysis used in version 1 of the submitteed paper
```{r echo=FALSE, warning = FALSE}

##Here we fit logistic regression to each participant
##The logitic regression is equivalent to the descriptive model without the bias term
##We use logistic regressions  instead of the full descriptive model becuase the latter would not converge given the small data points available for each participant


joint_bysub_1 <- joint_all_exp1 %>%
  group_by(ID) %>%
  do(fit_joint_1 = glm(answer ~ concept_dist+ sound_dist, data=., family = binomial()))

joint_bysub_2 <- joint_all_exp2 %>%
  group_by(ID) %>%
  do(fit_joint_2 = glm(answer ~ concept_dist+ sound_dist, data=., family = binomial()))

joint_bysub_3 <- joint_all_exp3 %>%
  group_by(ID) %>%
  do(fit_joint_3 = glm(answer ~ concept_dist+ sound_dist, data=., family = binomial()))

##Extract auitory and visual variances for each participant

#Exp1
bimodal_bysub_1 = tidy(joint_bysub_1, fit_joint_1) %>%
  filter(term == 'concept_dist' | term == 'sound_dist') %>%
  mutate(j_var = 4/(estimate)) %>%
  select(ID, term, j_var) %>%
  spread(term, j_var) %>%
  rename(j_c_var = concept_dist, 
         j_s_var = sound_dist) %>%
  mutate(bimod = j_c_var/j_s_var)

#Exp2
bimodal_bysub_2 = tidy(joint_bysub_2, fit_joint_2) %>%
  filter(term == 'concept_dist' | term == 'sound_dist') %>%
  mutate(j_var = 4/(estimate)) %>%
  select(ID, term, j_var) %>%
  spread(term, j_var) %>%
  rename(j_c_var = concept_dist, 
         j_s_var = sound_dist) %>%
  mutate(bimod = j_c_var/j_s_var)

#Exp3
bimodal_bysub_3 = tidy(joint_bysub_3, fit_joint_3) %>%
  filter(term == 'concept_dist' | term == 'sound_dist') %>%
  mutate(j_var = 4/(estimate)) %>%
  select(ID, term, j_var) %>%
  spread(term, j_var) %>%
  rename(j_c_var = concept_dist, 
         j_s_var = sound_dist) %>%
  mutate(bimod = j_c_var/j_s_var)
  
```

```{r echo=FALSE}
#number of participants relying exlusiviely on one modality
#cut off: a factor of 10

#participants who rely on both modalities 
bimodal_bysub_good_1 <- bimodal_bysub_1 %>%
  filter(bimod > 0.1) %>%
  filter(bimod < 10) 

#participants who rely only on the visual modality
#(this includes participants who relied  only on the visual modality but gave noisy responses, leading to negative values of the variance, probably due to mistaking "same" for "different", or vice versa)
only_visual_N_1 <- bimodal_bysub_1 %>%
  filter(abs(bimod) < 0.1) %>%
  nrow()

#participants who rely only on the auditory modality

only_sound_N_1 <- bimodal_bysub_1 %>%
  filter(abs(bimod) > 10) %>%
  nrow()

#participants who relied on both modalities 
both_N_1 <- bimodal_bysub_1 %>%
  filter(abs(bimod) > 0.1) %>%
  filter(abs(bimod) < 10) %>%
  nrow()

#participants with noisy negative variances
neg_N_1 <- bimodal_bysub_1 %>%
  filter(bimod <  -0.1) %>%
  filter(bimod > -10) %>%
  nrow()

#Proportion of participants who relied only on the visual modality
exlusive_prop_1 = only_visual_N_1/(only_sound_N_1+only_visual_N_1)

```



```{r echo=FALSE, warning = FALSE}

#Simulated individual data from descriptive model model_fit0 without a bias term (equivalent to logitic regression)
#(but the values are very similar to descriptive model with bias the term model_fit1)

simulations <- data.frame()

#We aggregate simulted values for 50 times the number of participants  (in order to get a stable final distribution)
for (i in 1:50) {
Simul_exp1 <- joint_all_exp1 %>%
  select(ID, sound_dist, concept_dist) %>%
  mutate(prob = model_fit0(sound_dist, concept_dist)) %>%
  rowwise() %>%
  mutate(answer = rbinom(1, 1, prob=prob))

joint_bysub_sim_1 <- Simul_exp1 %>%
  group_by(ID) %>%
  do(fit_joint_sim_1 = glm(answer ~ concept_dist+ sound_dist, data=., family = binomial()))

bimodal_bysub_sim_1 = tidy(joint_bysub_sim_1, fit_joint_sim_1) %>%
  filter(term == 'concept_dist' | term == 'sound_dist') %>%
  mutate(j_var = 4/(estimate)) %>%
  select(ID, term, j_var) %>%
  spread(term, j_var) %>%
  rename(j_c_var = concept_dist, 
         j_s_var = sound_dist) %>%
  mutate(bimod = j_c_var/j_s_var) %>%
  select(ID, bimod) %>%
  filter(bimod > 0.1) %>%
  filter(bimod < 10) 

  simulations <- bind_rows(simulations, bimodal_bysub_sim_1)
}
  


#Process and combine Real and Simulated data

  bimod_sim <- simulations  %>%
    mutate(data='simulation') 

  bimod_real <- bimodal_bysub_good_1  %>%
    select(ID, bimod) %>%
    mutate(data='real') 

                    
  bimod_all <- bind_rows(bimod_real, bimod_sim) 
  
 
#compare the sd of the distribtutions
 sd_ind<- bimod_all %>%
  group_by(data) %>%
  summarise(mean= mean(bimod),
            sd = sd(bimod))
```

```{r echo=FALSE, individual, out.width = "\\textwidth", fig.pos = "!h",fig.cap = "Distributions of individual values of the visual variance relative to the auditory variance in Experiment 1. Light color represents the real individual distribution, and dark color represents the simulated individual distribution sampled from the descriptive model."}

ggplot(data=bimod_all, aes(x=bimod, y=..ncount..)) +
  geom_histogram(data=subset(bimod_all, data=='real'), fill="red", alpha=0.2, binwidth = 0.2)+
  geom_histogram(data=subset(bimod_all, data=='simulation'), fill="blue", alpha=0.2, binwidth = 0.2)+
  #geom_histogram(binwidth = 0.2) +
  scale_x_log10() +
   xlab("Visual variance relative to sound variance") +ylab("Count")+
  theme_few()+
  theme(aspect.ratio = 0.7)
 

```
-->